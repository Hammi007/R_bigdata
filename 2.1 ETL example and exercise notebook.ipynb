{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ETL example and exercise notebook\n",
    "\n",
    "In this notebook the example data from the book and other data is loaded and examples of ETL is presented. Futhermore, there are exercises you can try out yourself."
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 Loading data into R\n",
    "\n",
    "In this section we will load different types of data into R.\n",
    "\n",
    "First we will load the data from the Books [Github page](https://github.com/jgendron/com.packtpub.intro.r.bi). You can see the raw data [here](https://raw.githubusercontent.com/jgendron/com.packtpub.intro.r.bi/master/Chapter1-ExtractTransformLoad/data/Ch1_bike_sharing_data.csv)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "url <- \"https://raw.githubusercontent.com/jgendron/com.packtpub.intro.r.bi/master/Chapter1-ExtractTransformLoad/data/Ch1_bike_sharing_data.csv\"\n",
    "bikeData <- read.csv(url)\n",
    "head(bikeData)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above command first store the url of the data in the a variable called `url`. Then, this variable is passed to the function `read.csv` that reads the data into the data frame `bikeData`. (So you can read csv files directly into R from the web without downloading the file first.)\n",
    "\n",
    "You can see the first 6 lines of the dataset by using the function `head` on `bikeData`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "head(bikeData)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you want to se another number of the first line, you can pass that number as the second argument to the `head` function. For instance, if you want to see the first 15 lines of the `bikeData` data frame, you can simply do:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "head(bikeData, 15)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Exercise*\n",
    "\n",
    "What do you think the `tail` function does? Try to read the help page by typing `?tail` and try using the `tail` function on the `bikeData` data frame below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tail(bikeData)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "While the `head` function gives you an example of the data by showing you the first lines, the `str` function will provide you with more information about the data frame. Try it out:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "str(bikeData)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see the `str` function tells you that `bikeData` is a `'data.frame'` and that it has 17379 rows and 12 columns. Moreover, for each column it tells you the name, the data type, and give you examples of the first couple of values. For instance, the `temp` variable is of numeric data type and the first couple of values are 9.84, 9.02, 9.02, ... Similar, `count` is an integer data type with the first couple of values 16, 40, 32, 13, ...\n",
    "\n",
    "The `datetime` variable is a `Factor` variable as you can also see from above. It also tells you the number of levels of the factor variable. In this case the number of factors is the same as the number of observations/rows. This should make you suspicious. What you really want is the `datetime` variable to be of some datetime data type. To get the datetime column imported as basic text string instead of factor, we can tell R to read all string variables as strings instead of factors (- by default R reads all string variables in as factors). To do this pass the argument `stringsAsFactors=FALSE` to the function reading in the data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bikeData <- read.csv(url, stringsAsFactors=FALSE)\n",
    "str(bikeData)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see the `datetime` column is now of type `chr` which means character (or text string)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading in excel files\n",
    "\n",
    "Let us try to import another dataset. This time we will load an excel sheet from a local folder. (What a \"local folder\" is depends, of course, on whether you are using the RUC Jupyter Hub, Azure Notebooks, or a local Jupyter installation.)\n",
    "\n",
    "If you are using RUC Jupyter Hub, you first need to upload the file. Go to the Jupyter home (clicking \"jupyter\" in the upper left corner). navigate to the folder of your current notebook and click the Upload button to upload a file. (Note that you cannot copy files in Jupyter Notebook. What you can do is to dublicate a file and then move the dublicate. You might not be able to do this in the course material folder due to writing restrictions. So instead you probably need to download the file to your local computer and then upload it to your home folder.)\n",
    "\n",
    "If you are using Azure Notebook, you first have to upload the file to a library. So you should start by uploading the file \"Webanalytics_data_example.xlsx\" (Find this on the Moodle page for todays lecture) to your library. To do this, from the Azure notebook library click the \"+ New\" and them \"From computer\". Click \"Choose file\" and then \"Upload\".\n",
    "\n",
    "If you are using a local installation of Jupyter Notebook, you just need to download the file from Moodle and place it in the folder where your notebook is stored.\n",
    "\n",
    "Alternatively you can change the path in the call to `read_excel` below or set the working directory to where your file is. To see what your current working directory is, use the function `getwd`. (To set the working directory, you can use the function `setwd`.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "getwd()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before we can read in the file, we need a function that can read excel files. Such a function, we can find in one of the packages tha comes with the \"tidyverse\" collection of packages. This collection of packages is already installed on the RUC Jupyter Hub and the Azure notebooks servers (if you work locally, you can install the packages using the command `install.packages(\"tidyverse\"))`. The particular package we need is called \"readxl\" and we load it with the following command:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "library(readxl)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The package \"readxl\" contains the function `read_excel` that we can use to read the file we just uploaded:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "webAnalyticsData <- read_excel(\"./Data/Webanalytics_data_example.xlsx\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us look at what we loaded in:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "head(webAnalyticsData)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Something seems weird here... If you open the file in Excel (try to do that), you will see that there are multiple sheets, and the one we loaded in is the first one. We want the second one, that is the sheet named \"Dataset1\". However, reading the help page for the function `read_excel` tell us that it is easily done by adding the argument `sheet = 2` or `sheet = \"Dataset1\"`. So try this:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "webAnalyticsData <- read_excel(\"./Data/Webanalytics_data_example.xlsx\", sheet = \"Dataset1\")\n",
    "head(webAnalyticsData)\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Exercise*\n",
    "\n",
    "Use the `str` function to figure out what the different data types are of the different columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "str(webAnalyticsData)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Exercise*\n",
    "\n",
    "Try to load the third sheet (\"Dataset2\") into a data frame called \"webAnalyticsData2\". (You might run into some problems. If so check the excel file and consider whether you need to skip some lines. Figure out how to do this by looking at the help page for the function `read_excel`. (If you manage to do it correctly, the cell below should give you a working plot.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "webAnalyticsData2 <- read_excel(\"./Data/Webanalytics_data_example.xlsx\", sheet = \"Dataset2\", skip = 2)\n",
    "str(webAnalyticsData2)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# If you did the exercise correctly, this code should give you a working plot\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "\n",
    "\n",
    "webAnalyticsData2 %>% select(Dates = contains(\"Day\"), Sessions) %>% ggplot(aes(Dates, Sessions)) + geom_line(color = \"blue\")\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 Transforming data in R \n",
    "\n",
    "Let us try to do some transformation on the data we have just loaded into R."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Exercise*\n",
    "\n",
    "Filter the `webAnalyticsData` data frame on the rows for which the bounce rate i bigger than 0.6.\n",
    "\n",
    "(Bounce rate is defined as the percentage of users who left a website immediately after going there, in other words they most likely ended there by mistake or did not find the website interesting. Thus this will give us an idea of which media channels provide the biggest fraction of useless visitors to the website.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Exercise*\n",
    "\n",
    "Filter the `webAnalyticsData` data frame on the rows fow which Transactions i bigger than 100 and Sessions is less than 30000\n",
    "\n",
    "(This give us media channels with a decent amount of transactions given not to many sessions. Thus, they are somewhat effective these media channels.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filter(webAnalyticsData, Transactions > 100 & Sessions < 30000)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Exercise*\n",
    "\n",
    "We can create a more precise measure for the effectiveness of a media channel by calculating the precentage of sessions that ended in a transaction. That is, for how many of the user sessions that the website had, did the user end up actually buying something. This is often refered to as the *conversion rate*.\n",
    "\n",
    "Use the `mutate` function to create a new column called `ConversionRate` that is equal to `Transactions/Sessions`. Which media channel had the highest conversion rate?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mutate(webAnalyticsData, ConversionRate =  Transactions/Sessions*100)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Exercise*\n",
    "\n",
    "We might instead be interested in the absolute revenue generated by the different media channels. To see this in a easier readable format, use the `select` function to only select the columns `MediaChannel` and `Revenue`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "select(webAnalyticsData, MediaChannel, Revenue)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Exercise*\n",
    "\n",
    "To make it even easier to see the media channel with the highest revenue, arrange the data frame such that the media channel with the highest revenue is at the top. (Hint: You need to use the `select` and `arrange` function at the same time. Thus, you might need to make a nested function call, or store the output of one of the calls in a temporary variable.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df <- select(webAnalyticsData, MediaChannel, Revenue)\n",
    "df %>% arrange(desc(df$Revenue)) \n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Exercise*\n",
    "\n",
    "We are interested in knowing the total revenue and conversion rate for paid and non-paid media. Thus we will group the media channels into paid and non-paid. Thus, first create a new column called `Type` which takes on the value `Paid` for the media channels `Paid_Search`, `Display` and `Email`. For the other channels the value should be `Non-paid` (it is of course debatable whether to put social in paid or non-paid here). To do this use `mutate` and the following expression to define the `Type` column: `ifelse(MediaChannel %in% c(\"Paid_Search\", \"Display\", \"Email\"), \"Paid\", \"Non-paid\")`. (Try to look up the help for the `ifelse` function and see if you can understand this code.)\n",
    "\n",
    "Store the output of this exercise in a data frame called `webAnalyticsDatawType`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mutate(webAnalyticsData, Type =  ifelse(MediaChannel %in% c(\"Paid_Search\", \"Display\", \"Email\"), \"Paid\", \"Non-paid\"))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Exercise*\n",
    "\n",
    "Use the data frame from the last exercise together with the `groupby` and `summerise` functions to create a data frame that shows the total revenue and total number of sessions for each to types `Paid` and `Non-paid` media. (Hint: It is probably easiest to make a nested function call with the `group_by` function as the inner function.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df <- mutate(webAnalyticsData, Type =  ifelse(MediaChannel %in% c(\"Paid_Search\", \"Display\", \"Email\"), \"Paid\", \"Non-paid\"))\n",
    "\n",
    "df %>%\n",
    "group_by(Type) %>%\n",
    "summarize(TotalRevenue = sum(Revenue), Session = sum(Sessions))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Exercise*\n",
    "\n",
    "Calculate the conversion rate for Paid and Non-paid media. (Hint: Use the `group_by` and `summarise` functions.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df %>%\n",
    "mutate(webAnalyticsData, ConversionRate =  Transactions/Sessions)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Exercise*\n",
    "\n",
    "Write the data frame of the last exercise to a csv file. Can you locate the file on RUC Jupyter Hub, Azure Notebooks, or your local machine and does it looks like you expected?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfType <- mutate(webAnalyticsData, Type =  ifelse(MediaChannel %in% c(\"Paid_Search\", \"Display\", \"Email\"), \"Paid\", \"Non-paid\"))\n",
    "\n",
    "newdf = dfType %>%\n",
    "group_by(Type) %>%\n",
    "summarize(ConversionRate = sum(Transactions/sum(Sessions)))\n",
    "\n",
    "write.csv(newdf, \"Amazing.csv\", row.names = FALSE)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R",
   "codemirror_mode": "r",
   "pygments_lexer": "r",
   "mimetype": "text/x-r-source",
   "file_extension": ".r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}